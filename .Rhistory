library(sp)
library(raster)
rasters15 <- list.files("./data/Raster", full.names = T)
rasters15 <- lapply(rasters15, raster)
mystack <- stack(rasters15)
setwd("..")
library(sp)
library(raster)
rasters15 <- list.files("./data/Raster", full.names = T)
rasters15 <- lapply(rasters15, raster)
mystack <- stack(rasters15)
template <- rasters15[[1]]
## load points
PA <- read.csv("./data/liuetal2019PA.csv")
envs1 <- extract(mystack, PA[,1:2])
envs <- envs1
envs[,2:5] <- apply(envs[,2:5], 2,function(w){ (w-mean(w,na.rm = T))/sd(w,na.rm = T)})
full <- cbind(PA,envs)
full <- na.omit(full)
Y <- full$R
X <- list(full[,4], full[,5:6], full[,7], full[,8])
X <- lapply(X, as.matrix)
# make predictions used
all_env <- as.matrix( getValues(mystack))
mean_env <- colMeans(envs1[,2:5], na.rm = T)
sd_env <- apply(envs1[,2:5],2,sd, na.rm = T)
allones <- rep(1,nrow(all_env))
# standardize
all_env[,2:5] <- (all_env[,2:5]-(allones %*% t(mean_env)))/(allones %*% t(sd_env))
Xpred <- list(all_env[,1], all_env[,2:3], all_env[,4], all_env[,5])
Xpred <- lapply(Xpred, as.matrix)
# try minlinear
source("./R/minlinlogistic.R")
set.seed(12345)
#fit <- minlinlogistic(Y,X, boot = 0, soft = FALSE,method = "SANN")
fit <- minlinlogistic(Y,X, boot = 0, a = 100,method = "SANN",control = list(maxit = 15000))
fit$fit$findmin
plot(roc(Y, fit$fit$predicted))
library(pROC)
plot(roc(Y, fit$fit$predicted))
# random forest
library(randomForest)
rffit <- randomForest(R~., data = full[,-c(1:2)])
plot(roc(Y, rffit$predicted))
rffit$importance
rffit$coefs
rffit$localImportance
full
glmfit <- glm(R~., data = full[,-c(1:2)], family = binomial())
plot(roc(Y, glmfit$fitted.values))
roc(Y, glmfit$fitted.values)
# see the differences between three methods
plot(glmfit$fitted.values, fit$fit$predicted)
plot(glmfit$fitted.values, rffit$predicted)
plot(fit$fit$predicted, rffit$predicted)
hist(glmfit$fitted.values-fit$fit$predicted)
hist(glmfit$fitted.values-rffit$predicted)
hist(fit$fit$predicted-rffit$predicted)
load("/media/yunyi/Academia/Collaborations/MinLinLogistic/Res/bootstrap_samples.rda")
w <- boot_sample[[1]]
w$opt$par
boot_par <- sapply(boot_sample, function(w){w$opt$par})
boot_par <- lapply(boot_sample, function(w){w$opt$par})
boot_sample
boot_par <- lapply(boot_sample$boot, function(w){w$opt$par})
boot_par <- sapply(boot_sample$boot, function(w){w$opt$par})
ww = boot_sample$boot
ww
boot_par <- sapply(boot_sample$boot, function(w){w$par})
boot_par <- sapply(boot_sample$boot, function(w){w$par}) |> t()
apply(boot_par, 2, sd)
boot_sample$fit$opt$par
names(mystack)
summary(glmfit)
rffit
rffit$importance
library(sp)
library(raster)
rasters15 <- list.files("./data/Raster", full.names = T)
rasters15 <- lapply(rasters15, raster)
mystack <- stack(rasters15)
template <- rasters15[[1]]
## load points
PA <- read.csv("./data/liuetal2019PA.csv")
envs1 <- extract(mystack, PA[,1:2])
envs <- envs1
envs[,2:5] <- apply(envs[,2:5], 2,function(w){ (w-mean(w,na.rm = T))/sd(w,na.rm = T)})
full <- cbind(PA,envs)
full <- na.omit(full)
Y <- full$R
X <- list(full[,4], full[,5:6], full[,7], full[,8])
X <- lapply(X, as.matrix)
# random forest
library(randomForest)
rffit <- randomForest(R~., data = full[,-c(1:2)])
rffit$localImportance
rffit$importance
varImpPlot(rffit, class = 2)
?varImpPlot
importance(rffit)
?randomForest
rffit_class <- randomForest(R~., data = full[,-c(1:2)], type = "classifiction")
rffit_class <- randomForest(as.factor(R)~., data = full[,-c(1:2)])
rffit_class$importance
plot(roc(Y, rffit$predicted))
library(qRoc)
library(qROC)
library(pROC)
plot(roc(Y, rffit$predicted))
plot(roc(Y, rffit_class$predicted))
rffit_class$importance
